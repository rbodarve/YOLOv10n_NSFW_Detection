{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E5eYtU1dkoRK"
      },
      "outputs": [],
      "source": [
        "#import shutil\n",
        "#shutil.rmtree('/content/sample_data', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7i7tLvPlSuS"
      },
      "source": [
        "# YOLOv10n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zDE3azwBlaEO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import subprocess\n",
        "import urllib.request\n",
        "import zipfile\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe26woeolfw5"
      },
      "source": [
        "Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lvsMShEImedz"
      },
      "outputs": [],
      "source": [
        "def install_requirements():\n",
        "    packages = [\n",
        "        \"ultralytics\",\n",
        "        \"torch\",\n",
        "        \"torchvision\",\n",
        "        \"tensorflow\",\n",
        "        \"onnx\",\n",
        "        \"onnx2tf\",\n",
        "        \"onnxsim\",\n",
        "    ]\n",
        "    # Prnt each \n",
        "    for package in packages:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
        "\n",
        "    print(\"All required packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2-oh6GLnFQE"
      },
      "source": [
        "Check for existing dataset or download COCO128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqJWe4dlnKgr"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset():\n",
        "    # List of common dataset locations to check\n",
        "    potential_datasets = [\n",
        "        \"/content/dataset\",\n",
        "        \"/content/custom_dataset\",\n",
        "        \"/content/yolo_dataset\",\n",
        "        \"/content/coco128\",\n",
        "        \"/dataset\",\n",
        "        \"/custom_dataset\",\n",
        "        \"/yolo_dataset\",\n",
        "        \"/coco128\"\n",
        "    ]\n",
        "    # Check for existing datasets\n",
        "    for dataset_path in potential_datasets:\n",
        "        if os.path.exists(dataset_path):\n",
        "            # Look for YOLO dataset structure (images and labels folders)\n",
        "            images_dir = os.path.join(dataset_path, 'images')\n",
        "            labels_dir = os.path.join(dataset_path, 'labels')\n",
        "\n",
        "            # Also check for common YOLO yaml files\n",
        "            yaml_files = [f for f in os.listdir(dataset_path) if f.endswith('.yaml') or f.endswith('.yml')]\n",
        "\n",
        "            if os.path.exists(images_dir) and os.path.exists(labels_dir):\n",
        "                # Check if folders have content\n",
        "                has_images = len([f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.bmp'))]) > 0\n",
        "                has_labels = len([f for f in os.listdir(labels_dir) if f.lower().endswith('.txt')]) > 0\n",
        "\n",
        "                if has_images and has_labels:\n",
        "                    print(f\"Existing dataset found at: {dataset_path}\")\n",
        "\n",
        "                    # Try to find or create a yaml file\n",
        "                    yaml_path = None\n",
        "                    if yaml_files:\n",
        "                        yaml_path = os.path.join(dataset_path, yaml_files[0])\n",
        "                        print(f\"Using existing yaml file: {yaml_files[0]}\")\n",
        "                    else:\n",
        "                        # Create a basic yaml file\n",
        "                        yaml_path = create_basic_yaml(dataset_path)\n",
        "\n",
        "                    return dataset_path, yaml_path\n",
        "    # No existing dataset found, download COCO128\n",
        "    print(\"No existing dataset found. Downloading COCO128...\")\n",
        "    coco128_path = download_coco128()\n",
        "    yaml_path = os.path.join(coco128_path, 'coco128.yaml')\n",
        "\n",
        "    return coco128_path, yaml_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A3JT_zjhnc-Y"
      },
      "outputs": [],
      "source": [
        "def create_basic_yaml(dataset_path):\n",
        "    yaml_content = f\"\"\"\n",
        "    # Dataset configuration\n",
        "    path: {dataset_path}\n",
        "    train: images\n",
        "    val: images\n",
        "\n",
        "    # Classes (will be auto-detected from labels)\n",
        "    nc: 80  # number of classes (placeholder)\n",
        "    names: ['class0', 'class1', 'class2']  # class names (placeholder)\n",
        "    \"\"\"\n",
        "    yaml_path = os.path.join(dataset_path, 'dataset.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"Created basic yaml configuration: {yaml_path}\")\n",
        "    return yaml_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "0t3NE8EBnlQ5"
      },
      "outputs": [],
      "source": [
        "def download_coco128():\n",
        "    dataset_url = \"https://github.com/ultralytics/yolov5/releases/download/v1.0/coco128.zip\"\n",
        "    dataset_path = \"/content/coco128.zip\"\n",
        "    extract_path = \"/content/\"\n",
        "\n",
        "    print(\"Downloading COCO128 dataset...\")\n",
        "    urllib.request.urlretrieve(dataset_url, dataset_path)\n",
        "\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_path)\n",
        "\n",
        "    # Remove zip file to save space\n",
        "    os.remove(dataset_path)\n",
        "\n",
        "    # Verify the yaml file exists and fix path if needed\n",
        "    coco128_dir = \"/content/coco128\"\n",
        "    yaml_file = os.path.join(coco128_dir, \"coco128.yaml\")\n",
        "\n",
        "    if not os.path.exists(yaml_file):\n",
        "        print(\"coco128.yaml not found, checking for alternative locations...\")\n",
        "        # Look for any yaml files in the directory\n",
        "        yaml_files = [f for f in os.listdir(coco128_dir) if f.endswith('.yaml') or f.endswith('.yml')]\n",
        "        if yaml_files:\n",
        "            print(f\"Found yaml file: {yaml_files[0]}\")\n",
        "        else:\n",
        "            print(\"No yaml file found, creating basic configuration...\")\n",
        "            create_coco128_yaml(coco128_dir)\n",
        "\n",
        "    print(\"COCO128 dataset downloaded and extracted successfully!\")\n",
        "    return coco128_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bXM1SyGprRpn"
      },
      "outputs": [],
      "source": [
        "def create_coco128_yaml(dataset_path):\n",
        "    yaml_content = f\"\"\"# COCO128 dataset configuration\n",
        "path: {dataset_path}\n",
        "train: images/train2017\n",
        "val: images/train2017\n",
        "\n",
        "# Classes\n",
        "nc: 80\n",
        "names: ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
        "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
        "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
        "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
        "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
        "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
        "        'hair drier', 'toothbrush']\n",
        "\"\"\"\n",
        "\n",
        "    yaml_path = os.path.join(dataset_path, 'coco128.yaml')\n",
        "    with open(yaml_path, 'w') as f:\n",
        "        f.write(yaml_content)\n",
        "\n",
        "    print(f\"Created coco128.yaml at: {yaml_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GDhXeI_nnoDT"
      },
      "outputs": [],
      "source": [
        "def train_yolov10n(yaml_path, epochs=100, imgsz=640):\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    print(\"Initializing YOLOv10n model...\")\n",
        "    model = YOLO('yolov10n.pt')  # Load pretrained YOLOv10n model\n",
        "\n",
        "    print(f\"Starting training for {epochs} epochs...\")\n",
        "    print(f\"Using dataset configuration: {yaml_path}\")\n",
        "\n",
        "    results = model.train(\n",
        "        data=yaml_path,\n",
        "        epochs=epochs,\n",
        "        imgsz=imgsz,\n",
        "        batch=16,\n",
        "        device=0 if os.system('nvidia-smi') == 0 else 'cpu',  # Use GPU if available\n",
        "        project='/content/yolov10_training',\n",
        "        name='training_experiment',\n",
        "        save=True,\n",
        "        cache=True,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    print(\"Training completed!\")\n",
        "    return model, results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_er9x-WMnqTL"
      },
      "outputs": [],
      "source": [
        "# Export model to different formats\n",
        "def export_model_formats(model, export_dir=\"/content/exported_models\"):\n",
        "    os.makedirs(export_dir, exist_ok=True)\n",
        "\n",
        "    print(\"Exporting model to different formats...\")\n",
        "\n",
        "    # Export to ONNX (intermediate format for TensorFlow conversion)\n",
        "    onnx_path = model.export(format='onnx', dynamic=False, simplify=True)\n",
        "    print(f\"ONNX model exported to: {onnx_path}\")\n",
        "\n",
        "    # Export to TensorFlow SavedModel format\n",
        "    try:\n",
        "        tf_path = model.export(format='saved_model')\n",
        "        print(f\"TensorFlow SavedModel exported to: {tf_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Direct TensorFlow export failed: {e}\")\n",
        "        tf_path = None\n",
        "\n",
        "    return onnx_path, tf_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Gsyv4-F5ntlw"
      },
      "outputs": [],
      "source": [
        "# Convert ONNX to TensorFlow Lite\n",
        "def convert_to_tflite(onnx_path, output_dir=\"/content/tflite_models\"):\n",
        "    import tensorflow as tf\n",
        "\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    try:\n",
        "        # First convert ONNX to TensorFlow SavedModel using onnx2tf\n",
        "        print(\"Converting ONNX to TensorFlow SavedModel...\")\n",
        "        saved_model_dir = f\"{output_dir}/saved_model\"\n",
        "\n",
        "        # Use onnx2tf for conversion\n",
        "        cmd = f\"onnx2tf -i {onnx_path} -o {saved_model_dir} --non_verbose\"\n",
        "        subprocess.run(cmd, shell=True, check=True)\n",
        "\n",
        "        # Convert TensorFlow SavedModel to TensorFlow Lite\n",
        "        print(\"Converting TensorFlow SavedModel to TensorFlow Lite...\")\n",
        "        converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "\n",
        "        # Optimization settings for mobile deployment\n",
        "        converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "        converter.target_spec.supported_types = [tf.float16]  # Use FP16 for smaller size\n",
        "\n",
        "        # Convert the model\n",
        "        tflite_model = converter.convert()\n",
        "\n",
        "        # Save the TensorFlow Lite model\n",
        "        tflite_path = f\"{output_dir}/yolov10n_coco128.tflite\"\n",
        "        with open(tflite_path, 'wb') as f:\n",
        "            f.write(tflite_model)\n",
        "\n",
        "        print(f\"TensorFlow Lite model saved to: {tflite_path}\")\n",
        "\n",
        "        # Get model size\n",
        "        model_size = os.path.getsize(tflite_path) / (1024 * 1024)  # Size in MB\n",
        "        print(f\"TensorFlow Lite model size: {model_size:.2f} MB\")\n",
        "\n",
        "        return tflite_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"TensorFlow Lite conversion failed: {e}\")\n",
        "        print(\"Trying alternative conversion method...\")\n",
        "\n",
        "        # Alternative method using TensorFlow directly\n",
        "        try:\n",
        "            # Load and convert the ONNX model differently\n",
        "            import onnx\n",
        "            import tf2onnx\n",
        "\n",
        "            print(\"Attempting alternative conversion...\")\n",
        "            # This is a placeholder for alternative conversion logic\n",
        "            # You might need to implement a custom conversion pipeline\n",
        "\n",
        "            return None\n",
        "\n",
        "        except Exception as e2:\n",
        "            print(f\"Alternative conversion also failed: {e2}\")\n",
        "            return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "upBLr45wnw52"
      },
      "outputs": [],
      "source": [
        "def validate_tflite_model(tflite_path, test_image_path=None):\n",
        "    import tensorflow as tf\n",
        "    import numpy as np\n",
        "\n",
        "    # Load TFLite model and allocate tensors\n",
        "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
        "    interpreter.allocate_tensors()\n",
        "\n",
        "    # Get input and output tensors\n",
        "    input_details = interpreter.get_input_details()\n",
        "    output_details = interpreter.get_output_details()\n",
        "\n",
        "    print(\"TensorFlow Lite Model Validation:\")\n",
        "    print(f\"Input shape: {input_details[0]['shape']}\")\n",
        "    print(f\"Input type: {input_details[0]['dtype']}\")\n",
        "    print(f\"Number of outputs: {len(output_details)}\")\n",
        "\n",
        "    for i, output in enumerate(output_details):\n",
        "        print(f\"Output {i} shape: {output['shape']}\")\n",
        "        print(f\"Output {i} type: {output['dtype']}\")\n",
        "\n",
        "    # Test with random input if no test image provided\n",
        "    if test_image_path is None:\n",
        "        input_shape = input_details[0]['shape']\n",
        "        test_input = np.random.random(input_shape).astype(np.float32)\n",
        "\n",
        "        interpreter.set_tensor(input_details[0]['index'], test_input)\n",
        "        interpreter.invoke()\n",
        "\n",
        "        print(\"Test inference completed successfully!\")\n",
        "\n",
        "        # Get outputs\n",
        "        for i, output in enumerate(output_details):\n",
        "            output_data = interpreter.get_tensor(output['index'])\n",
        "            print(f\"Output {i} min/max: {output_data.min():.4f}/{output_data.max():.4f}\")\n",
        "\n",
        "    return True\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F-WiBlQbn3Ab"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    print(\"=== YOLOv10n Training and TensorFlow Lite Conversion Pipeline ===\")\n",
        "    try:\n",
        "        # Step 1: Install requirements\n",
        "        print(\"\\n1. Installing required packages...\")\n",
        "        install_requirements()\n",
        "\n",
        "        # Step 2: Check for existing dataset or prepare COCO128\n",
        "        print(\"\\n2. Checking for existing dataset...\")\n",
        "        dataset_path, yaml_path = prepare_dataset()\n",
        "\n",
        "        # Step 3: Train model\n",
        "        print(\"\\n3. Training YOLOv10n model...\")\n",
        "        model, results = train_yolov10n(yaml_path, epochs=50)  # Reduced for faster training\n",
        "\n",
        "        # Step 4: Export model formats\n",
        "        print(\"\\n4. Exporting model to different formats...\")\n",
        "        onnx_path, tf_path = export_model_formats(model)\n",
        "\n",
        "        # Step 5: Convert to TensorFlow Lite\n",
        "        print(\"\\n5. Converting to TensorFlow Lite...\")\n",
        "        tflite_path = convert_to_tflite(onnx_path)\n",
        "\n",
        "        if tflite_path:\n",
        "            # Step 6: Validate TFLite model\n",
        "            print(\"\\n6. Validating TensorFlow Lite model...\")\n",
        "            validate_tflite_model(tflite_path)\n",
        "        else:\n",
        "            print(\"\\n=== Pipeline Completed with Errors ===\")\n",
        "            print(\"TensorFlow Lite conversion failed. Check the ONNX model output.\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nPipeline failed with error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2YJzGee_n-D3"
      },
      "outputs": [],
      "source": [
        "# Alternative simplified conversion function\n",
        "def simple_tflite_conversion():\n",
        "    from ultralytics import YOLO\n",
        "\n",
        "    print(\"Running simplified TensorFlow Lite conversion...\")\n",
        "\n",
        "    # Load pre-trained YOLOv10n\n",
        "    model = YOLO('yolov10n.pt')\n",
        "\n",
        "    # Direct export to TensorFlow Lite (if supported)\n",
        "    try:\n",
        "        tflite_path = model.export(format='tflite', imgsz=640)\n",
        "        print(f\"Direct TFLite export successful: {tflite_path}\")\n",
        "        return tflite_path\n",
        "    except Exception as e:\n",
        "        print(f\"Direct TFLite export failed: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ4RRCuPoBLN",
        "outputId": "98e0bedb-e337-4504-a086-cb998ccf26dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting YOLOv10n training and TensorFlow Lite conversion...\n",
            "Note: This process may take 1-2 hours depending on training epochs and hardware.\n",
            "=== YOLOv10n Training and TensorFlow Lite Conversion Pipeline ===\n",
            "\n",
            "1. Installing required packages...\n",
            "All required packages installed successfully!\n",
            "\n",
            "2. Checking for existing dataset...\n",
            "No existing dataset found. Downloading COCO128...\n",
            "Downloading COCO128 dataset...\n",
            "Extracting dataset...\n",
            "coco128.yaml not found, checking for alternative locations...\n",
            "No yaml file found, creating basic configuration...\n",
            "Created coco128.yaml at: /content/coco128/coco128.yaml\n",
            "COCO128 dataset downloaded and extracted successfully!\n",
            "\n",
            "3. Training YOLOv10n model...\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Initializing YOLOv10n model...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov10n.pt to 'yolov10n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.6MB 104.8MB/s 0.1s\n",
            "Starting training for 50 epochs...\n",
            "Using dataset configuration: /content/coco128/coco128.yaml\n",
            "Ultralytics 8.3.202 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=True, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/coco128/coco128.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=training_experiment, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/yolov10_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolov10_training/training_experiment, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 126.0MB/s 0.0s\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
            " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
            " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
            " 23        [16, 19, 22]  1    929808  ultralytics.nn.modules.head.v10Detect        [80, [64, 128, 256]]          \n",
            "YOLOv10n summary: 223 layers, 2,775,520 parameters, 2,775,504 gradients, 8.7 GFLOPs\n",
            "\n",
            "Transferred 595/595 items from pretrained weights\n",
            "Freezing layer 'model.23.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 216.9MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1072.3Â±386.2 MB/s, size: 46.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 2.2Kit/s 0.1s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/coco128/labels/train2017.cache\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.1GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 318.5it/s 0.4s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 474.2Â±100.5 MB/s, size: 63.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 21.4Kit/s 0.0s\n",
            "WARNING âš ï¸ cache='ram' may produce non-deterministic training results. Consider cache='disk' as a deterministic alternative if your disk space allows.\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB RAM): 100% â”â”â”â”â”â”â”â”â”â”â”â” 128/128 138.7it/s 0.9s\n",
            "Plotting labels to /content/yolov10_training/training_experiment/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolov10_training/training_experiment\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/50      3.25G      2.528      2.986      2.501        228        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 0.5it/s 16.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 0.2it/s 16.9s\n",
            "                   all        128        929      0.634      0.582      0.629      0.467\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/50      4.65G      2.637      2.828      2.423        205        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.5it/s 0.9s\n",
            "                   all        128        929       0.67      0.583      0.663      0.489\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/50      4.68G      2.687       2.91      2.496        125        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.5it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        128        929       0.72      0.582      0.682      0.508\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/50      4.69G      2.577      2.657      2.419        180        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929       0.74      0.591       0.69      0.522\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/50      4.69G      2.369      2.597      2.363        250        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.741      0.619      0.699      0.528\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/50      4.69G       2.39      2.513      2.398        233        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.1it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.1it/s 1.3s\n",
            "                   all        128        929       0.76      0.621      0.711      0.541\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/50      4.69G       2.44       2.55      2.341        231        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929       0.74      0.665      0.722      0.547\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/50      4.71G      2.507      2.521      2.391        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.765      0.651      0.734      0.561\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/50      4.72G      2.333       2.43      2.338        122        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.2it/s 1.2s\n",
            "                   all        128        929        0.8      0.649      0.751      0.577\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/50      4.92G      2.287      2.293      2.291        175        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.2it/s 2.5s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.5it/s 0.9s\n",
            "                   all        128        929      0.803      0.648      0.756      0.583\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      11/50      4.94G      2.399      2.277      2.316        244        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.5it/s 0.9s\n",
            "                   all        128        929        0.8      0.666      0.769      0.596\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      12/50      4.94G      2.397      2.349      2.322        242        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.788      0.689      0.776      0.604\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      13/50      4.94G      2.242      2.179        2.3        186        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 3.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.816      0.684      0.782      0.605\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      14/50      4.94G      2.212      2.178      2.315        227        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.827      0.703      0.796      0.625\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      15/50      4.94G      2.323      2.121        2.3        244        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.5it/s 0.9s\n",
            "                   all        128        929      0.822      0.706        0.8      0.631\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      16/50      4.94G      2.222      2.117       2.26        176        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.6it/s 1.1s\n",
            "                   all        128        929       0.85      0.712      0.807      0.636\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      17/50      4.94G      2.208      2.014      2.199        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.842      0.714      0.807       0.64\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      18/50      4.94G      2.305      2.042      2.218        179        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.815       0.75      0.816      0.642\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      19/50      4.94G      2.286      2.045      2.239        199        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.4it/s 1.2s\n",
            "                   all        128        929      0.832      0.737      0.818       0.65\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      20/50      4.94G      2.199      2.013      2.203        293        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.861      0.732      0.823      0.655\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      21/50      4.94G      2.173      1.915      2.229        220        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.869       0.74       0.83      0.658\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      22/50      4.94G      2.239      2.034      2.202        200        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.0it/s 1.0s\n",
            "                   all        128        929      0.842      0.756      0.833      0.659\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      23/50      4.94G      2.133      1.994      2.229        216        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.866      0.742      0.832      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      24/50      4.94G      2.189      1.953      2.234        194        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.867      0.738      0.834      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      25/50      4.94G      2.214       1.95      2.192        187        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.834      0.757      0.831      0.661\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      26/50      4.94G      2.148      1.895      2.163        250        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.5it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 0.9s\n",
            "                   all        128        929      0.828      0.764      0.836      0.667\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      27/50      4.94G      2.126       1.88       2.17        171        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.836      0.772       0.84      0.672\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      28/50      4.94G      2.129       1.89      2.197        249        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.848      0.766      0.842      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      29/50      4.94G      2.079      1.784      2.133        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.0it/s 2.6s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.3it/s 1.2s\n",
            "                   all        128        929      0.882      0.748      0.843      0.675\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      30/50      4.94G      2.251      1.889      2.199        258        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.4it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929       0.88      0.754      0.843       0.68\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      31/50      4.94G       2.16       1.81      2.157        207        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.846      0.772      0.844      0.679\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      32/50      4.94G      1.952      1.751      2.148        163        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.3it/s 1.2s\n",
            "                   all        128        929      0.853      0.765      0.846      0.684\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      33/50      4.94G      2.197      1.828      2.144        238        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.8it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.876       0.75      0.846      0.683\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      34/50      4.94G      2.049      1.768      2.169        224        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.859      0.758      0.845      0.685\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      35/50      4.94G      2.151      1.796      2.131        229        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.2it/s 1.0s\n",
            "                   all        128        929      0.837      0.776      0.846      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      36/50      4.94G      2.121      1.778      2.125        201        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.5it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929       0.86      0.776      0.851      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      37/50      4.94G      2.058      1.794      2.167        191        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.881      0.762      0.852      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      38/50      4.94G      2.014      1.697      2.094        255        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.1it/s 1.0s\n",
            "                   all        128        929        0.9       0.75      0.852      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      39/50      4.94G      2.041      1.675      2.125        159        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.7it/s 2.9s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.6it/s 1.1s\n",
            "                   all        128        929      0.847      0.776      0.854      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      40/50      4.94G      1.992      1.682      2.119        168        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.5it/s 2.3s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.897       0.76      0.855      0.698\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      41/50      4.94G      1.983      1.599      2.042         86        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.2it/s 3.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.7it/s 1.1s\n",
            "                   all        128        929      0.908       0.75      0.851      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      42/50      4.94G      2.065      1.609      2.057        121        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.5it/s 3.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.874      0.764      0.852      0.694\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      43/50      4.94G      1.983      1.567      2.035         94        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.884      0.759      0.857      0.693\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      44/50      4.94G      2.032      1.633      2.089        105        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.864      0.767      0.863      0.695\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      45/50      4.94G      1.925      1.481      1.982         78        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.0it/s 2.7s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.0it/s 1.3s\n",
            "                   all        128        929      0.869      0.765      0.853      0.696\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      46/50      4.94G      2.075      1.706      2.074        154        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.8it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.4it/s 0.9s\n",
            "                   all        128        929      0.845      0.778      0.849      0.692\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      47/50      4.94G      1.949      1.548      2.037         60        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.8it/s 2.1s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        128        929      0.905      0.727      0.847       0.69\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      48/50      4.94G      1.935      1.547      2.021        103        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.6it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 3.9it/s 1.0s\n",
            "                   all        128        929      0.841       0.77      0.846      0.688\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      49/50      4.94G      2.004      1.502      2.026        123        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 2.9it/s 2.8s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.837      0.768      0.845      0.689\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      50/50      4.94G      1.918      1.468      2.047         82        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 8/8 3.7it/s 2.2s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 4.3it/s 0.9s\n",
            "                   all        128        929      0.875      0.756      0.847       0.69\n",
            "\n",
            "50 epochs completed in 0.063 hours.\n",
            "Optimizer stripped from /content/yolov10_training/training_experiment/weights/last.pt, 5.9MB\n",
            "Optimizer stripped from /content/yolov10_training/training_experiment/weights/best.pt, 5.9MB\n",
            "\n",
            "Validating /content/yolov10_training/training_experiment/weights/best.pt...\n",
            "Ultralytics 8.3.202 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv10n summary (fused): 102 layers, 2,299,264 parameters, 0 gradients, 6.7 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 4/4 1.6it/s 2.6s\n",
            "                   all        128        929      0.897      0.759      0.855      0.698\n",
            "                person         61        254      0.946      0.683      0.852      0.667\n",
            "               bicycle          3          6      0.727        0.5      0.614      0.428\n",
            "                   car         12         46      0.894      0.365      0.595       0.29\n",
            "            motorcycle          4          5      0.857          1      0.995       0.89\n",
            "              airplane          5          6       0.92          1      0.995      0.924\n",
            "                   bus          5          7       0.85      0.714      0.864      0.747\n",
            "                 train          3          3       0.88          1      0.995      0.845\n",
            "                 truck          5         12      0.963        0.5      0.657      0.443\n",
            "                  boat          2          6          1      0.616      0.839      0.683\n",
            "         traffic light          4         14      0.808      0.357      0.402      0.246\n",
            "             stop sign          2          2       0.81          1      0.995      0.895\n",
            "                 bench          5          9      0.696      0.667      0.864      0.694\n",
            "                  bird          2         16          1      0.868      0.991      0.817\n",
            "                   cat          4          4      0.885          1      0.995      0.953\n",
            "                   dog          9          9      0.929      0.889      0.975      0.922\n",
            "                 horse          1          2          1          1      0.995      0.846\n",
            "              elephant          4         17      0.992      0.941      0.964      0.875\n",
            "                  bear          1          1       0.71          1      0.995      0.895\n",
            "                 zebra          2          4      0.894          1      0.995      0.977\n",
            "               giraffe          4          9      0.873          1      0.984      0.891\n",
            "              backpack          4          6      0.738      0.667      0.705      0.574\n",
            "              umbrella          4         18      0.864      0.833       0.94      0.764\n",
            "               handbag          9         19       0.87      0.353      0.564      0.412\n",
            "                   tie          6          7          1      0.676       0.86      0.657\n",
            "              suitcase          2          4      0.905          1      0.995      0.843\n",
            "               frisbee          5          5      0.867        0.8      0.807      0.731\n",
            "                  skis          1          1      0.771          1      0.995      0.796\n",
            "             snowboard          2          7       0.97      0.857      0.944      0.791\n",
            "           sports ball          6          6       0.96      0.667      0.672      0.337\n",
            "                  kite          2         10          1      0.456      0.677      0.315\n",
            "          baseball bat          4          4      0.946       0.75      0.748      0.461\n",
            "        baseball glove          4          7          1      0.546      0.587      0.322\n",
            "            skateboard          3          5      0.933        0.6      0.729      0.557\n",
            "         tennis racket          5          7          1      0.559      0.721      0.488\n",
            "                bottle          6         18          1      0.362      0.767       0.54\n",
            "            wine glass          5         16      0.813      0.545       0.77      0.481\n",
            "                   cup         10         36      0.865      0.533      0.839      0.599\n",
            "                  fork          6          6      0.982      0.667      0.834      0.632\n",
            "                 knife          7         16          1      0.545      0.797      0.516\n",
            "                 spoon          5         22          1      0.449       0.71      0.485\n",
            "                  bowl          9         28      0.942       0.75      0.842      0.742\n",
            "                banana          1          1      0.755          1      0.995      0.995\n",
            "              sandwich          2          2      0.795          1      0.995      0.995\n",
            "                orange          1          4          1      0.885      0.995      0.759\n",
            "              broccoli          4         11          1      0.336      0.733      0.581\n",
            "                carrot          3         24      0.816      0.833      0.918      0.663\n",
            "               hot dog          1          2      0.826          1      0.995      0.995\n",
            "                 pizza          5          5      0.911          1      0.995      0.959\n",
            "                 donut          2         14      0.931      0.971       0.99      0.928\n",
            "                  cake          4          4      0.898          1      0.995      0.959\n",
            "                 chair          9         35      0.774      0.486      0.796      0.596\n",
            "                 couch          5          6      0.804      0.667      0.845      0.666\n",
            "          potted plant          9         14      0.876      0.929      0.948       0.72\n",
            "                   bed          3          3      0.896          1      0.995       0.93\n",
            "          dining table         10         13       0.83       0.75       0.83      0.711\n",
            "                toilet          2          2      0.855          1      0.995      0.948\n",
            "                    tv          2          2       0.81          1      0.995      0.849\n",
            "                laptop          2          3      0.733          1      0.995      0.913\n",
            "                 mouse          2          2      0.876          1      0.995      0.597\n",
            "                remote          5          8      0.878      0.625      0.709      0.576\n",
            "            cell phone          5          8          1      0.521      0.644      0.425\n",
            "             microwave          3          3          1          1      0.995      0.914\n",
            "                  oven          5          5      0.814        0.6      0.608      0.581\n",
            "                  sink          4          6          1      0.594      0.769      0.581\n",
            "          refrigerator          5          5       0.75          1      0.995       0.87\n",
            "                  book          6         29      0.915      0.371      0.768      0.515\n",
            "                 clock          8          9      0.905      0.889      0.956      0.818\n",
            "                  vase          2          2          1      0.842      0.995      0.895\n",
            "              scissors          1          1          1          0      0.249     0.0505\n",
            "            teddy bear          6         21          1      0.846      0.965      0.784\n",
            "            toothbrush          2          5      0.974          1      0.995      0.822\n",
            "Speed: 0.5ms preprocess, 3.1ms inference, 0.0ms loss, 0.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolov10_training/training_experiment\u001b[0m\n",
            "Training completed!\n",
            "\n",
            "4. Exporting model to different formats...\n",
            "Exporting model to different formats...\n",
            "Ultralytics 8.3.202 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "ğŸ’¡ ProTip: Export to OpenVINO format for best performance on Intel hardware. Learn more at https://docs.ultralytics.com/integrations/openvino/\n",
            "YOLOv10n summary (fused): 102 layers, 2,299,264 parameters, 0 gradients, 6.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov10_training/training_experiment/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.6 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['onnxslim>=0.1.67', 'onnxruntime-gpu'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 5.9s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.68...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 7.9s, saved as '/content/yolov10_training/training_experiment/weights/best.onnx' (9.0 MB)\n",
            "\n",
            "Export complete (8.4s)\n",
            "Results saved to \u001b[1m/content/yolov10_training/training_experiment/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/yolov10_training/training_experiment/weights/best.onnx imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/yolov10_training/training_experiment/weights/best.onnx imgsz=640 data=/content/coco128/coco128.yaml  \n",
            "Visualize:       https://netron.app\n",
            "ONNX model exported to: /content/yolov10_training/training_experiment/weights/best.onnx\n",
            "Ultralytics 8.3.202 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLOv10n summary (fused): 102 layers, 2,299,264 parameters, 0 gradients, 6.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from '/content/yolov10_training/training_experiment/weights/best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.6 MB)\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirements ['sng4onnx>=1.0.1', 'onnx_graphsurgeon>=0.3.26', 'ai-edge-litert>=1.2.0'] not found, attempting AutoUpdate...\n",
            "\n",
            "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 7.1s\n",
            "WARNING âš ï¸ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/calibration_image_sample_data_20x128x128x3_float32.npy.zip to 'calibration_image_sample_data_20x128x128x3_float32.npy.zip': 100% â”â”â”â”â”â”â”â”â”â”â”â” 1.1MB 114.7MB/s 0.0s\n",
            "\u001b[KUnzipping calibration_image_sample_data_20x128x128x3_float32.npy.zip to /content/calibration_image_sample_data_20x128x128x3_float32.npy...: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 35.8files/s 0.0s\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.68...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 1.8s, saved as '/content/yolov10_training/training_experiment/weights/best.onnx' (9.0 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
            "Saved artifact at '/content/yolov10_training/training_experiment/weights/best_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 300, 6), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136721823384976: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136721823384592: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  136721823385360: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136721823388816: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136721823389392: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  136721823388432: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136721823389584: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  136721823389776: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136721823390352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823390160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823392656: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136721823393040: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136721823389968: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136721823385936: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136721823390544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823390736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722099269328: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  136722099269136: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136722099268752: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136722099270288: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136722099268944: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722099268368: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722099267984: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722127231440: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722127231248: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722127231824: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136722127231056: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136722099269520: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136722099268560: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136721823386512: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136721823391888: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136721823393616: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136721823394000: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136722127230864: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722127231632: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823394384: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136721823393808: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721823384400: TensorSpec(shape=(1, 1, 64, 128), dtype=tf.float32, name=None)\n",
            "  136721823394576: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721823394960: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136721823395344: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136721823394768: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721823394192: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136721823395536: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721823396112: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823395920: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823398032: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721823398224: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721823395152: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721823395728: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721823397456: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721823398416: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721823397072: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721823398800: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721823396304: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823396496: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721823399184: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136721823398608: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721823397648: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136721823399376: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721823398992: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136721820942416: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
            "  136721823399568: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721823399760: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136721820942608: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820943376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820943184: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820945296: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136721820945488: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820942800: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136721820942992: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820943568: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820943760: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820945680: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136721820944336: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820944720: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136721820946064: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820946256: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136721820946448: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820944912: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136721820946640: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820946832: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136721820945872: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820950288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136721820947216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820953168: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136721820950864: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820952016: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136721820952976: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820948368: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136721820953552: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820950480: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136721820953744: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820952208: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  136721820952784: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820952592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820951824: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820955664: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820955856: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820953360: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820952400: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820953936: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820954128: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820956240: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136721820956048: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820955280: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  136721820955088: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820956816: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820956624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820957584: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136721820958544: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136721820956432: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136721820954704: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136721820957008: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820957200: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820957776: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  136721820958352: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098618832: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136721820958160: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722098619024: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098621136: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136722098620560: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722098622672: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098622864: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098624592: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722098623632: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098624016: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722098626128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098622480: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098621712: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098625552: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136722098625744: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722098626704: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136722098627280: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722098625936: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136722098624976: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136722098627472: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722098628240: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136722098627664: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722098629392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098628624: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098630544: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136722098629584: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722098632272: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136722098629200: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722098633040: TensorSpec(shape=(7, 7, 256, 1), dtype=tf.float32, name=None)\n",
            "  136722098632848: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722098633616: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136722098634576: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722098632080: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136722098632464: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722098629776: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098629968: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722098619792: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
            "  136722098619984: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098633808: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136722098632656: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722098620752: TensorSpec(shape=(1, 1, 64, 80), dtype=tf.float32, name=None)\n",
            "  136722098619216: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098633232: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
            "  136722098627088: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136722098634384: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722098626896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722109710800: TensorSpec(shape=(1, 1, 256, 80), dtype=tf.float32, name=None)\n",
            "  136722098627856: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136722098622288: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  136722109710416: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098624400: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098623440: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722109710608: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  136722098633424: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136722098628432: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  136722098621520: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136722098619600: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109711568: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098634192: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098629008: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098623824: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098619408: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098625168: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722098624784: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722109711952: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722098634000: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722098631504: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722098625360: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722098620368: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109711184: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098631120: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098631696: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098626320: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098620176: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109712144: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722109710992: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722098630928: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722098628816: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722098623056: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722098621328: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109711376: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109712336: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098628048: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098631888: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722098622096: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722098626512: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722109714448: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109711760: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109715600: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136722109716752: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109714832: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109713488: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109712912: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109715216: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136722109716944: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136722109713104: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109713296: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136722109718864: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
            "  136722109720592: TensorSpec(shape=(2, 1), dtype=tf.int32, name=None)\n",
            "  136722109721744: TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n",
            "  136722109717520: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
            "  136722109718288: TensorSpec(shape=(2, 1), dtype=tf.int32, name=None)\n",
            "  136722109719824: TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n",
            "  136722109722320: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  136722109722128: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 36.9s, saved as '/content/yolov10_training/training_experiment/weights/best_saved_model' (23.4 MB)\n",
            "\n",
            "Export complete (37.4s)\n",
            "Results saved to \u001b[1m/content/yolov10_training/training_experiment/weights\u001b[0m\n",
            "Predict:         yolo predict task=detect model=/content/yolov10_training/training_experiment/weights/best_saved_model imgsz=640  \n",
            "Validate:        yolo val task=detect model=/content/yolov10_training/training_experiment/weights/best_saved_model imgsz=640 data=/content/coco128/coco128.yaml  \n",
            "Visualize:       https://netron.app\n",
            "TensorFlow SavedModel exported to: /content/yolov10_training/training_experiment/weights/best_saved_model\n",
            "\n",
            "5. Converting to TensorFlow Lite...\n",
            "Converting ONNX to TensorFlow SavedModel...\n",
            "Converting TensorFlow SavedModel to TensorFlow Lite...\n",
            "TensorFlow Lite model saved to: /content/tflite_models/yolov10n_coco128.tflite\n",
            "TensorFlow Lite model size: 4.91 MB\n",
            "\n",
            "6. Validating TensorFlow Lite model...\n",
            "TensorFlow Lite Model Validation:\n",
            "Input shape: [  1 640 640   3]\n",
            "Input type: <class 'numpy.float32'>\n",
            "Number of outputs: 1\n",
            "Output 0 shape: [  1 300   6]\n",
            "Output 0 type: <class 'numpy.float32'>\n",
            "Test inference completed successfully!\n",
            "Output 0 min/max: -21.8782/661.8129\n",
            "Running simplified TensorFlow Lite conversion...\n",
            "Ultralytics 8.3.202 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CPU (Intel Xeon CPU @ 2.20GHz)\n",
            "YOLOv10n summary (fused): 102 layers, 2,299,264 parameters, 0 gradients, 6.7 GFLOPs\n",
            "\n",
            "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'yolov10n.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 300, 6) (5.6 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.0 opset 19...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.68...\n",
            "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 2.2s, saved as 'yolov10n.onnx' (9.1 MB)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m starting TFLite export with onnx2tf 1.28.2...\n",
            "Saved artifact at 'yolov10n_saved_model'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serving_default'\n",
            "  inputs_0 (POSITIONAL_ONLY): TensorSpec(shape=(1, 640, 640, 3), dtype=tf.float32, name='images')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(1, 300, 6), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  136720727520464: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136720727520656: TensorSpec(shape=(3, 3, 3, 16), dtype=tf.float32, name=None)\n",
            "  136720727520272: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136720727519888: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136720727520080: TensorSpec(shape=(3, 3, 16, 32), dtype=tf.float32, name=None)\n",
            "  136720727521040: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136720727519504: TensorSpec(shape=(1, 1, 32, 32), dtype=tf.float32, name=None)\n",
            "  136720727519312: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136720727518544: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727518736: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727516624: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136720727516432: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136720727512592: TensorSpec(shape=(3, 3, 16, 16), dtype=tf.float32, name=None)\n",
            "  136720727519696: TensorSpec(shape=(16,), dtype=tf.float32, name=None)\n",
            "  136720727518352: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727518160: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727516240: TensorSpec(shape=(1, 1, 48, 32), dtype=tf.float32, name=None)\n",
            "  136720727517584: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136720727515856: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136720727517200: TensorSpec(shape=(3, 3, 32, 64), dtype=tf.float32, name=None)\n",
            "  136720727516048: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136720727515664: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136720727515472: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136720727514896: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727515088: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727512976: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136720727512784: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136720727515280: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136720727517008: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136720727513552: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136720727512400: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136720727513936: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136720727512016: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136720727514704: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727514512: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727511632: TensorSpec(shape=(1, 1, 128, 64), dtype=tf.float32, name=None)\n",
            "  136720727512208: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136720727513360: TensorSpec(shape=(1, 1, 64, 128), dtype=tf.float32, name=None)\n",
            "  136720727511440: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136720727511056: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136720727510672: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136720727511248: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136720727511824: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136720727510480: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136720727509904: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727510096: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727507984: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136720727507792: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136720727510864: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136720727510288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136720727508560: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136720727507600: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136720727508944: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136720727507216: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136720727509712: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727509520: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136720727507408: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136720727507024: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136720727508368: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136722127231248: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722127231056: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136722127231632: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
            "  136722127231824: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722127231440: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136722127230864: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722099268752: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722099269136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722099268368: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136722099269904: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722099269520: TensorSpec(shape=(3, 3, 128, 128), dtype=tf.float32, name=None)\n",
            "  136722099269712: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722099270288: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722099268944: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722099267984: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136722099269328: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722109726352: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136722109726160: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722109725968: TensorSpec(shape=(1, 1, 512, 256), dtype=tf.float32, name=None)\n",
            "  136722109720400: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722109725584: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136722109720784: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722109717904: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136722109725776: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722109724816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  136722109721936: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722109724432: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136722109724048: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722109721552: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136722109723664: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722109723472: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136722109719632: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722109724624: TensorSpec(shape=(1, 1, 256, 256), dtype=tf.float32, name=None)\n",
            "  136722109717136: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722109725008: TensorSpec(shape=(1, 1, 384, 128), dtype=tf.float32, name=None)\n",
            "  136722109717328: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722109718480: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109717712: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109711952: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109711184: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109712528: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109719056: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109716560: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109725392: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109710992: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136722109712144: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136722109710608: TensorSpec(shape=(1, 1, 192, 64), dtype=tf.float32, name=None)\n",
            "  136722109710416: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109714448: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109712336: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109713296: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136722109718864: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136722109711376: TensorSpec(shape=(3, 3, 32, 32), dtype=tf.float32, name=None)\n",
            "  136722109720208: TensorSpec(shape=(32,), dtype=tf.float32, name=None)\n",
            "  136722109711760: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109715600: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109721744: TensorSpec(shape=(1, 1, 96, 64), dtype=tf.float32, name=None)\n",
            "  136722109720592: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109717520: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136722109715216: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109713488: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109714640: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136722109723088: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820949136: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820942416: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109716176: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109715408: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820946256: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820944336: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109716368: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820943376: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820946064: TensorSpec(shape=(1, 1, 192, 128), dtype=tf.float32, name=None)\n",
            "  136721820943568: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820946832: TensorSpec(shape=(1, 1, 128, 128), dtype=tf.float32, name=None)\n",
            "  136721820947216: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820946448: TensorSpec(shape=(4, 2), dtype=tf.int32, name=None)\n",
            "  136721820943184: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136721820953168: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820948368: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136721820950864: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820952592: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820950480: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820953936: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136721820951824: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820958544: TensorSpec(shape=(1, 1, 128, 256), dtype=tf.float32, name=None)\n",
            "  136721820952784: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820957200: TensorSpec(shape=(7, 7, 256, 1), dtype=tf.float32, name=None)\n",
            "  136721820957008: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820958160: TensorSpec(shape=(1, 1, 256, 128), dtype=tf.float32, name=None)\n",
            "  136721820954896: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820957584: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136721820956432: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820955664: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136721820955856: TensorSpec(shape=(4,), dtype=tf.int64, name=None)\n",
            "  136722109722320: TensorSpec(shape=(3, 3, 64, 1), dtype=tf.float32, name=None)\n",
            "  136722109722128: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820957968: TensorSpec(shape=(1, 1, 384, 256), dtype=tf.float32, name=None)\n",
            "  136721820954704: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136722109718096: TensorSpec(shape=(1, 1, 64, 80), dtype=tf.float32, name=None)\n",
            "  136722109716944: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820957776: TensorSpec(shape=(3, 3, 256, 1), dtype=tf.float32, name=None)\n",
            "  136721820950288: TensorSpec(shape=(3, 3, 128, 1), dtype=tf.float32, name=None)\n",
            "  136721820955472: TensorSpec(shape=(256,), dtype=tf.float32, name=None)\n",
            "  136721820945872: TensorSpec(shape=(128,), dtype=tf.float32, name=None)\n",
            "  136721820944144: TensorSpec(shape=(1, 1, 256, 80), dtype=tf.float32, name=None)\n",
            "  136721820952016: TensorSpec(shape=(1, 1, 128, 80), dtype=tf.float32, name=None)\n",
            "  136722109714064: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  136721820957392: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820945680: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722109715024: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721823384208: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  136721820958352: TensorSpec(shape=(3, 3, 256, 64), dtype=tf.float32, name=None)\n",
            "  136721820953552: TensorSpec(shape=(3, 3, 80, 1), dtype=tf.float32, name=None)\n",
            "  136721820942800: TensorSpec(shape=(3, 3, 128, 64), dtype=tf.float32, name=None)\n",
            "  136722109719824: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820944528: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820954512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820952208: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820942992: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109718288: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109713872: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722109712720: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820954320: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136721820956048: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820955088: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136721820944720: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136722109715792: TensorSpec(shape=(3, 3, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721823384592: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820951248: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820956816: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820944912: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136722109722512: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721823385360: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136721820945104: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820956240: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136721820953744: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820943760: TensorSpec(shape=(1, 1, 80, 80), dtype=tf.float32, name=None)\n",
            "  136722109715984: TensorSpec(shape=(1, 1, 64, 64), dtype=tf.float32, name=None)\n",
            "  136721820943952: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721823388816: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721820952976: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820956624: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136722109714256: TensorSpec(shape=(64,), dtype=tf.float32, name=None)\n",
            "  136721820946640: TensorSpec(shape=(80,), dtype=tf.float32, name=None)\n",
            "  136721823390544: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823384976: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823394384: TensorSpec(shape=(1, 1, 16, 1), dtype=tf.float32, name=None)\n",
            "  136721823389776: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823390352: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823392656: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823394768: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823390160: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823389584: TensorSpec(shape=(3,), dtype=tf.int64, name=None)\n",
            "  136721823393616: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136721823394192: TensorSpec(shape=(1, 2, 8400), dtype=tf.float32, name=None)\n",
            "  136721823391696: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
            "  136721823398992: TensorSpec(shape=(2, 1), dtype=tf.int32, name=None)\n",
            "  136721823399568: TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n",
            "  136721823396304: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
            "  136721823395344: TensorSpec(shape=(2, 1), dtype=tf.int32, name=None)\n",
            "  136721823397840: TensorSpec(shape=(2,), dtype=tf.int32, name=None)\n",
            "  136721823389200: TensorSpec(shape=(), dtype=tf.float32, name=None)\n",
            "  136721823398800: TensorSpec(shape=(), dtype=tf.int64, name=None)\n",
            "\u001b[34m\u001b[1mTensorFlow SavedModel:\u001b[0m export success âœ… 20.6s, saved as 'yolov10n_saved_model' (23.7 MB)\n",
            "\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m starting export with tensorflow 2.19.0...\n",
            "\u001b[34m\u001b[1mTensorFlow Lite:\u001b[0m export success âœ… 0.0s, saved as 'yolov10n_saved_model/yolov10n_float32.tflite' (9.4 MB)\n",
            "\n",
            "Export complete (21.4s)\n",
            "Results saved to \u001b[1m/content\u001b[0m\n",
            "Predict:         yolo predict task=detect model=yolov10n_saved_model/yolov10n_float32.tflite imgsz=640  \n",
            "Validate:        yolo val task=detect model=yolov10n_saved_model/yolov10n_float32.tflite imgsz=640 data=None  \n",
            "Visualize:       https://netron.app\n",
            "Direct TFLite export successful: yolov10n_saved_model/yolov10n_float32.tflite\n"
          ]
        }
      ],
      "source": [
        "# Execute the main pipeline\n",
        "if __name__ == \"__main__\":\n",
        "    # Run in Google Colab environment\n",
        "    print(\"Starting YOLOv10n training and TensorFlow Lite conversion...\")\n",
        "    print(\"Note: This process may take 1-2 hours depending on training epochs and hardware.\")\n",
        "\n",
        "    # Uncomment the line below to run the full pipeline\n",
        "    main()\n",
        "\n",
        "    # For quick testing, uncomment the line below\n",
        "    simple_tflite_conversion()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
